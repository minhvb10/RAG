{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n",
        "!pip install sentence-transformers faiss-gpu-cu12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq3ursfBdM4i",
        "outputId": "ea176d47-a5c8-4549-a068-f665860b8ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.1.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: faiss-gpu-cu12 in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (25.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from faiss-gpu-cu12) (12.6.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q sentence-transformers git+https://github.com/huggingface/transformers@v4.56.0-Embedding-Gemma-preview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKWp5doDZzY",
        "outputId": "95b1b384-1541-4237-af2d-53b9e748cf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pypdf import PdfReader\n",
        "import faiss\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "nS8eKHrvJ6E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "in8yEUsocngH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=512, overlap=50):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=overlap,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "egcIOLsKeFdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rag_system(pdf_path, fine_tuned_model_path):\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    chunks = chunk_text(text)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    # Load the fine-tuned model\n",
        "    embedding_model = SentenceTransformer(fine_tuned_model_path, token=userdata.get('HF_TOKEN')).to(device=device)\n",
        "    # Load the reranker model\n",
        "    reranker = CrossEncoder('BAAI/bge-reranker-v2-m3', device=device)\n",
        "    # Initialize the Gemini API\n",
        "    GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    gemini_model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "    # Create embeddings for the chunks\n",
        "    chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
        "    # Build a FAISS index\n",
        "    index = faiss.IndexFlatL2(chunk_embeddings.shape[1])\n",
        "    index.add(chunk_embeddings.cpu().detach().numpy())\n",
        "\n",
        "    def retrieve(query, top_k=10):\n",
        "        query_embedding = embedding_model.encode([query], convert_to_tensor=True)\n",
        "        scores, top_k_indices = index.search(query_embedding.cpu().detach().numpy(), k=top_k)\n",
        "        # Retrieve the top_k chunks\n",
        "        initial_retrieved_chunks_with_indices = [(chunks[i], i) for i in top_k_indices[0]]\n",
        "        # Prepare for reranking: create pairs of (query, chunk)\n",
        "        rerank_pairs = [[query, chunk] for chunk, _ in initial_retrieved_chunks_with_indices]\n",
        "        # Rerank the retrieved chunks\n",
        "        rerank_scores = reranker.predict(rerank_pairs)\n",
        "        # Sort chunks based on reranker scores and get the original indices\n",
        "        reranked_sorted_indices = np.argsort(rerank_scores)[::-1]\n",
        "        reranked_original_indices = [initial_retrieved_chunks_with_indices[i][1] for i in reranked_sorted_indices]\n",
        "        # Return the top 1 reranked chunk using original indices\n",
        "        return [chunks[i] for i in reranked_original_indices[:1]]\n",
        "\n",
        "    def generate_answer(query, context):\n",
        "        prompt = f\"\"\"\n",
        "        You are a helpful assistant that answers questions based on the provided context.\n",
        "        Context:\n",
        "        {\"\".join(context)}\n",
        "        Question:\n",
        "        {query}\n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        response = gemini_model.generate_content(prompt)\n",
        "        return response.text\n",
        "\n",
        "    return retrieve, generate_answer"
      ],
      "metadata": {
        "id": "sL4PuEfjjuMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    pdf_path = \"/content/2501.00309v2.pdf\"\n",
        "\n",
        "    fine_tuned_model_path = 'google/embeddinggemma-300m'\n",
        "\n",
        "    retriever, generator = build_rag_system(pdf_path, fine_tuned_model_path)\n",
        "\n",
        "    user_query = \"What is Neo4j?\"\n",
        "    retrieved_context = retriever(user_query)\n",
        "    final_answer = generator(user_query, retrieved_context)\n",
        "\n",
        "    print(\"\\n--- Final Answer ---\")\n",
        "    print(final_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "s6vvRZBQrtNA",
        "outputId": "eb979688-eade-4c47-ff2f-1475e764665e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Answer ---\n",
            "Based on the provided context, Neo4j is a graph database platform that offers a comprehensive set of tools for storing, visualizing, managing, and querying graph data. It also includes an LLM Graph Builder for extracting graphs with LLMs and provides GraphRAG demos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qyna159wvSW8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}